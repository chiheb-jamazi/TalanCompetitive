{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from getpass import getpass\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from hdfs import InsecureClient\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def twitter(comp):\n",
    "    company=comp\n",
    "    def get_tweet_data(card):\n",
    "        \"\"\"Extract data from tweet card\"\"\"\n",
    "        username = card.find_element_by_xpath('.//span').text\n",
    "        try:\n",
    "            handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "        except NoSuchElementException:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "        except NoSuchElementException:\n",
    "            return\n",
    "\n",
    "        comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "        responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    #     text = comment + responding\n",
    "        reply_cnt = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "        retweet_cnt = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "        like_cnt = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "\n",
    "        # get a string of all emojis contained in the tweet\n",
    "        \"\"\"Emojis are stored as images... so I convert the filename, which is stored as unicode, into \n",
    "        the emoji character.\"\"\"\n",
    "        list_img = card.find_elements_by_class_name('css-9pa8cd')\n",
    "        for img in list_img:\n",
    "            images = img.get_attribute(\"src\")\n",
    "\n",
    "        tweet = (username, handle, postdate, comment,responding, images, reply_cnt, retweet_cnt, like_cnt)\n",
    "        return tweet \n",
    "\n",
    "    driver=webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    sleep(3)\n",
    "    #Login\n",
    "    driver.get('https://twitter.com/login')\n",
    "    sleep(5)\n",
    "    username = driver.find_element_by_xpath('//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[5]/label').send_keys('jamazichiheb')\n",
    "    driver.find_element_by_xpath('//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[6]').click()\n",
    "    sleep(3)\n",
    "    password = driver.find_element_by_xpath('//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[3]/div/label/div/div[2]/div[1]/input').send_keys('Seawaymn2011&&')\n",
    "    sleep(3)\n",
    "    driver.find_element_by_xpath('//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div[1]').click()\n",
    "    sleep(4)\n",
    "\n",
    "\n",
    "    \n",
    "    page = \"https://twitter.com/\"+company+\"/\"\n",
    "    driver.get(page)\n",
    "\n",
    "\n",
    "    # get all tweets on the page\n",
    "    data = []\n",
    "    tweet_ids = set()\n",
    "    last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    scrolling = True\n",
    "\n",
    "    while scrolling:\n",
    "        page_cards = driver.find_elements_by_xpath('//article[@data-testid=\"tweet\"]')\n",
    "        for card in page_cards[-15:]:\n",
    "            tweet = get_tweet_data(card)\n",
    "            if tweet:\n",
    "                tweet_id = ''.join(tweet)\n",
    "                if tweet_id not in tweet_ids:\n",
    "                    tweet_ids.add(tweet_id)\n",
    "                    data.append(tweet)\n",
    "\n",
    "        scroll_attempt = 0\n",
    "        while True:\n",
    "            # check scroll position\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            sleep(2)\n",
    "            curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "            if last_position == curr_position:\n",
    "                scroll_attempt += 1\n",
    "\n",
    "                # end of scroll region\n",
    "                if scroll_attempt >= 3:\n",
    "                    scrolling = False\n",
    "                    break\n",
    "                else:\n",
    "                    sleep(2) # attempt another scroll\n",
    "            else:\n",
    "                last_position = curr_position\n",
    "                break\n",
    "\n",
    "    # close the web driver\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "    company=comp\n",
    "    file_name= company+'_twitter_df'\n",
    "    hdfs_url = \"http://localhost:9870/\"\n",
    "    hdfs_user = \"chiheb\"\n",
    "    c = InsecureClient(hdfs_url, user=hdfs_user)\n",
    "    c.makedirs(\"/user/chiheb/\"+company) \n",
    "    with c.write('accenture/'+file_name, encoding = 'utf-8') as f:\n",
    "        header = ['UserName', 'Handle', 'Timestamp',  'comment','responding', 'images', 'Comments', 'Likes', 'Retweets']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
