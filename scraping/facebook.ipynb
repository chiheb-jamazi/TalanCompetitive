{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from hdfs import InsecureClient\n",
    "def facebook(comp):\n",
    "    company=comp\n",
    "    def connect_to_facebook():\n",
    "        #open the webpage\n",
    "        driver.get(\"http://www.facebook.com\")\n",
    "\n",
    "        #target username\n",
    "        username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "        password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "        #enter username and password\n",
    "        username.clear()\n",
    "        username.send_keys(\"chihebjamazi@gmail.com\")\n",
    "        password.clear()\n",
    "        password.send_keys(\"Seawaymn2022&&\")\n",
    "\n",
    "        #target the login button and click it\n",
    "        button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "    def scrolling_function():\n",
    "        start = time.time()\n",
    "        initialScroll = 0\n",
    "        finalScroll = 1000\n",
    "\n",
    "        while True:\n",
    "            driver.execute_script(f\"window.scrollTo({initialScroll},{finalScroll})\")\n",
    "            initialScroll = finalScroll\n",
    "            finalScroll += 1000\n",
    "            end = time.time()\n",
    "            if round(end - start) > 30:\n",
    "                break \n",
    "    dates =[]\n",
    "    likes=[]\n",
    "    descriptions=[]\n",
    "    comments=[]\n",
    "    shares=[]\n",
    "    images=[]\n",
    "    article_links= []\n",
    "    def get_facebook_posts(soup):\n",
    "        containers =soup.find_all(class_='du4w35lb l9j0dhe7')\n",
    "        for container in containers :\n",
    "            try :\n",
    "                date = container.find(class_=\"tojvnm2t a6sixzi8 abs2jz4q a8s20v7p t1p8iaqh k5wvi7nf q3lfd5jv pk4s997a bipmatt0 cebpdrjk qowsmv63 owwhemhu dp1hu0rb dhp61c6y iyyx5f41\")\n",
    "                x = date.find('a')\n",
    "                dates.append(x['aria-label'])\n",
    "    #             print(dates)\n",
    "            except :\n",
    "                dates.append('none')\n",
    "            ###Description######\n",
    "            try :\n",
    "                description = container.find(class_=\"kvgmc6g5 cxmmr5t8 oygrvhab hcukyx3x c1et5uql ii04i59q\")\n",
    "                descriptions.append(description.get_text())\n",
    "    #             print(descriptions)\n",
    "            except :\n",
    "                descriptions.append('none')\n",
    "            ###Likes######\n",
    "            try:\n",
    "                reaction = container.find(class_ = 'pcp91wgn')\n",
    "                likes.append(reaction.get_text())\n",
    "    #             print(likes)\n",
    "            except :\n",
    "                likes.append('none')\n",
    "            ###comments_count######\n",
    "            try :\n",
    "                reaction = container.find(class_ = 'd2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d3f4x2em iv3no6db gfeo3gy3 a3bd9o3v b1v8xokw m9osqain')\n",
    "                comments.append(reaction[0].get_text())\n",
    "    #             print(comments)\n",
    "            except:\n",
    "                comments.append('none')\n",
    "            ###shares_count ######  \n",
    "            try :\n",
    "                reaction = container.find_all(class_ = 'd2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d3f4x2em iv3no6db gfeo3gy3 a3bd9o3v b1v8xokw m9osqain')\n",
    "                shares.append(reaction[1].get_text())\n",
    "    #             print(shares)\n",
    "            except :\n",
    "                shares.append('none')\n",
    "            ###images link ###### \n",
    "            try :\n",
    "                reaction = container.find(class_ = 'i09qtzwb n7fi1qx3 datstx6m pmk7jnqg j9ispegn kr520xx4 k4urcfbm bixrwtb6')\n",
    "                images.append(reaction['src'])\n",
    "    #             print(images)\n",
    "            except :\n",
    "                images.append('none')\n",
    "            try : \n",
    "\n",
    "                reaction = container.find(class_ = 'oajrlxb2 g5ia77u1 qu0x051f esr5mh6w e9989ue4 r7d6kgcz rq0escxv nhd2j8a9 nc684nl6 p7hjln8o kvgmc6g5 cxmmr5t8 oygrvhab hcukyx3x jb3vyjys rz4wbd8a qt6c0cv9 a8nywdso i1ao9s8h esuyzwwr f1sip0of lzcic4wl gmql0nx0 gpro0wi8 datstx6m k4urcfbm')\n",
    "                article_links.append(reaction['href'])\n",
    "    #             print(article_links)\n",
    "            except :\n",
    "                article_links.append('none')\n",
    "\n",
    "        return dates, likes, descriptions, comments, shares, images, article_links\n",
    "\n",
    "    \n",
    "    page = \"https://www.facebook.com/\"+company+\"/\"\n",
    "    # driver = webdriver.Chrome(r'C:\\\\Users\\\\jchih\\\\\\Documents\\\\selenium\\\\chromedriver.exe')\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "    chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "    connect_to_facebook()\n",
    "    time.sleep(2)\n",
    "    driver.get(page + 'posts/')\n",
    "    scrolling_function()\n",
    "    company_page = driver.page_source\n",
    "    soup =BeautifulSoup(company_page, 'lxml')\n",
    "    data = get_facebook_posts(soup)\n",
    "    driver.close()\n",
    "    list_Data = pd.DataFrame(\n",
    "                    {'PostDate': dates,\n",
    "                     'PostText': descriptions,\n",
    "                     'PostLikes': likes,       \n",
    "                     \"PostComments\":comments,\n",
    "                     \"PostShares\": shares,\n",
    "                     \"PostImages\":images,\n",
    "                     \"PostArticles\":article_links,\n",
    "                    })\n",
    "    \n",
    "    company=comp\n",
    "    file_name= company+'_facebook_df'\n",
    "    hdfs_url = \"http://localhost:9870/\"\n",
    "    hdfs_user = \"chiheb\"\n",
    "    c = InsecureClient(hdfs_url, user=hdfs_user)\n",
    "    c.makedirs(\"/user/chiheb/\"+company) \n",
    "    with c.write(company+'/'+file_name, encoding = 'utf-8') as writer:\n",
    "        list_Data.to_csv(writer,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
