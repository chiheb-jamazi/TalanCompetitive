{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "from time import sleep\n",
    "import time \n",
    "from hdfs import InsecureClient\n",
    "\n",
    "def linkedin(comp):\n",
    "    company=comp\n",
    "    def connect_to_linkedin ():\n",
    "        driver.get(\"https://www.linkedin.com/checkpoint/lg/sign-in-another-account\")\n",
    "        time.sleep(5)\n",
    "    #     username = driver.find_element_by_id(\"username\")\n",
    "        username = driver.find_element(By.ID,\"username\")\n",
    "        username.send_keys(\"chiheb.jamazi@esprit.tn\")\n",
    "    #     pword = driver.find_element_by_id(\"password\")\n",
    "        pword = driver.find_element(By.ID,\"password\")\n",
    "        pword.send_keys(\"Seawaymn2011&&\")\n",
    "    #     driver.find_element_by_xpath(\"//button[@type='submit']\").click()\n",
    "        driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "\n",
    "    def scrolling_function ():\n",
    "        SCROLL_PAUSE_TIME = 1.5\n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            #uncomment to limit the number of scrolls\n",
    "            #scroll_number += 1\n",
    "            # Wait to load page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        return\n",
    "\n",
    "    def get_posts_details(soupe):\n",
    "        poste_date =[] \n",
    "        post_text = []\n",
    "        post_nbreagi = []\n",
    "        post_nb_comm = []\n",
    "        post_nb_partage = []\n",
    "        post_video_link = []\n",
    "        containers =soupe.find_all('div', {'class':'occludable-update ember-view'})\n",
    "\n",
    "        for container in containers:\n",
    "            try:\n",
    "                his=container.find('span', class_ =\"visually-hidden\")\n",
    "        #         print(his.get_text().strip())\n",
    "                poste_date.append(his.get_text().strip())\n",
    "            except:\n",
    "                poste_date.append('none')\n",
    "            try:\n",
    "                text=container.find('span', class_ =\"break-words\")\n",
    "        #         print(text.get_text().strip())\n",
    "                post_text.append(text.get_text().strip())\n",
    "            except:\n",
    "                post_text.append('none')\n",
    "            try:\n",
    "                nbreagi=container.find('span', class_ =\"social-details-social-counts__reactions-count\")\n",
    "        #         print(nbreagi.get_text().strip())\n",
    "                post_nbreagi.append(nbreagi.get_text().strip())\n",
    "            except:\n",
    "                post_nbreagi.append('none')  \n",
    "            try:       \n",
    "                nb_comm=container.find('button',class_=\"t-black--light t-12 hoverable-link-text\")\n",
    "        #         print(nb_comm.get_text().strip())\n",
    "                post_nb_comm.append(nb_comm.get_text().strip())\n",
    "            except:\n",
    "                post_nb_comm.append('none')        \n",
    "\n",
    "            try:        \n",
    "                nb_partage=container.find('li',class_=\"social-details-social-counts__item social-details-social-counts__item--with-social-proof\")\n",
    "        #         print(nb_partage.get_text().strip())\n",
    "                post_nb_partage.append(nb_partage.get_text().strip())\n",
    "            except:\n",
    "                post_nb_partage.append('none')\n",
    "        return poste_date,post_text,post_nbreagi,post_nb_comm,post_nb_partage\n",
    "\n",
    "    def get_video_details(soupe):\n",
    "        post_video_link = []\n",
    "        containers =soupe.find_all('div', {'class':'occludable-update ember-view'})    \n",
    "        for container in containers :\n",
    "            try:\n",
    "                video_link=container.find('video',class_=\"vjs-tech\")\n",
    "                videolink= video_link['src']\n",
    "                post_video_link.append(videolink)\n",
    "            except:\n",
    "                post_video_link.append('none')\n",
    "        return post_video_link        \n",
    "\n",
    "    def get_Articles_details(soupe):\n",
    "        articles = [] \n",
    "        containers =soupe.find_all('div', {'class':'occludable-update ember-view'})    \n",
    "        for container in containers :\n",
    "            try : \n",
    "                article_link = container.find(\"article\")\n",
    "                articles.append(article_link.a['href'])\n",
    "            except:\n",
    "                articles.append('none')\n",
    "        return articles        \n",
    "\n",
    "    def get_images_details(soupe):\n",
    "        images = []\n",
    "        containers =soupe.find_all('div', {'class':'occludable-update ember-view'})    \n",
    "        for container in containers : \n",
    "            try:\n",
    "                spans = container.find_all('img')\n",
    "                image = spans[1]['src']\n",
    "                images.append(image)  \n",
    "            except :\n",
    "                images.append('None') \n",
    "        return images\n",
    "\n",
    "\n",
    "    company = comp\n",
    "    page = \"https://www.linkedin.com/company/\"+company+\"/\"\n",
    "    # driver=webdriver.Chrome(r'C:\\\\Users\\\\jchih\\\\\\Documents\\\\selenium\\\\chromedriver.exe')\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    connect_to_linkedin ()\n",
    "    x=''\n",
    "    y=''\n",
    "    for i in [\"videos\", \"articles\",\"images\"]:\n",
    "        try :\n",
    "            driver.get(page+\"posts/?feedView=\"+i) \n",
    "            scrolling_function ()\n",
    "            src =driver.page_source\n",
    "            soupe =BeautifulSoup(src, 'lxml')\n",
    "            data1 = get_posts_details(soupe)\n",
    "            if i == 'videos':\n",
    "                data2 = tuple(get_video_details(soupe))\n",
    "                data = data1 + data2\n",
    "                VideoData = pd.DataFrame(\n",
    "                {'PostDate': data[0],\n",
    "                 'PostText': data[1],\n",
    "                 'PostLikes': data[2],       \n",
    "                 \"PostComments\":data[3],\n",
    "                 \"PostShares\": data[4],\n",
    "                 \"Postlink\":data[5],\n",
    "                 \"Postype\" : \"video\",\n",
    "                })\n",
    "            elif i == 'articles':\n",
    "                data2 = tuple(get_Articles_details(soupe))\n",
    "                data = data1 + data2\n",
    "                ArticlesData = pd.DataFrame(\n",
    "                {'PostDate': data[0],\n",
    "                 'PostText': data[1],\n",
    "                 'PostLikes': data[2],       \n",
    "                 \"PostComments\":data[3],\n",
    "                 \"PostShares\": data[4],\n",
    "                 \"Postlink\":data[5],\n",
    "                 \"Postype\" : \"article\",\n",
    "                })\n",
    "            elif i == 'images':\n",
    "                data2 = tuple(get_images_details(soupe))\n",
    "                data = data1 + data2\n",
    "                ImagesData = pd.DataFrame(\n",
    "                {'PostDate': data[0],\n",
    "                 'PostText': data[1],\n",
    "                 'PostLikes': data[2],       \n",
    "                 \"PostComments\":data[3],\n",
    "                 \"PostShares\": data[4],\n",
    "                 \"Postlink\":data[5],\n",
    "                 \"Postype\" : \"image\",\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        except :\n",
    "            print('we have an error')\n",
    "\n",
    "\n",
    "    Posts = pd.concat([ImagesData, ArticlesData, VideoData],axis=0)\n",
    "\n",
    "    company=comp\n",
    "    file_name= company+'_linkedin_df'\n",
    "    hdfs_url = \"http://localhost:9870/\"\n",
    "    hdfs_user = \"chiheb\"\n",
    "    c = InsecureClient(hdfs_url, user=hdfs_user)\n",
    "    c.makedirs(\"/user/chiheb/\"+company) \n",
    "    with c.write(company+'/'+file_name, encoding = 'utf-8') as writer:\n",
    "        Posts.to_csv(writer,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
