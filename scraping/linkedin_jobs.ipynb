{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd \n",
    "from time import sleep\n",
    "import time \n",
    "import csv\n",
    "from hdfs import InsecureClient\n",
    "\n",
    "\n",
    "def jobs(comp):\n",
    "    company=comp\n",
    "    def connect_to_linkedin ():\n",
    "        driver.get(\"https://www.linkedin.com/checkpoint/lg/sign-in-another-account\")\n",
    "        time.sleep(5)\n",
    "    #     username = driver.find_element_by_id(\"username\")\n",
    "        username = driver.find_element(By.ID,\"username\")\n",
    "        username.send_keys(\"chiheb.jamazi@esprit.tn\")\n",
    "    #     pword = driver.find_element_by_id(\"password\")\n",
    "        pword = driver.find_element(By.ID,\"password\")\n",
    "        pword.send_keys(\"Seawaymn2011&&\")\n",
    "    #     driver.find_element_by_xpath(\"//button[@type='submit']\").click()\n",
    "        driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "\n",
    "    def scrolling_function ():\n",
    "        SCROLL_PAUSE_TIME = 1.5\n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            #uncomment to limit the number of scrolls\n",
    "            #scroll_number += 1\n",
    "            # Wait to load page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        return \n",
    "\n",
    "    Job_post_date =[] \n",
    "    company_name = []\n",
    "    job_title = []\n",
    "    job_links = []\n",
    "    Number_applicants = []\n",
    "    location = []\n",
    "    working_Place = []\n",
    "    def get_linkedin_jobs (soup):\n",
    "\n",
    "        containers = soup.find_all(class_='jobs-search-results__list-item occludable-update p0 relative ember-view')\n",
    "        for container in containers:\n",
    "            try:              \n",
    "                his=container.find(class_='job-card-container__listed-time job-card-container__footer-item')  \n",
    "                Job_post_date.append(his.get_text(strip =True))\n",
    "            except:\n",
    "                Job_post_date.append('none')\n",
    "            try:\n",
    "                text=container.find(class_='job-card-container__link job-card-container__company-name ember-view')\n",
    "                company_name.append(text.get_text(strip =True))\n",
    "            except:\n",
    "                company_name.append('none')\n",
    "            try:\n",
    "                desc=container.find(class_='disabled ember-view job-card-container__link job-card-list__title')\n",
    "                job_title.append(desc.get_text(strip =True))\n",
    "            except:\n",
    "                job_title.append('none')  \n",
    "            try:       \n",
    "                desc=container.find(class_='disabled ember-view job-card-container__link job-card-list__title')\n",
    "                descs = 'https://www.linkedin.com'+desc['href']\n",
    "                job_links.append(descs)\n",
    "            except:\n",
    "                job_links.append('none')        \n",
    "\n",
    "            try:        \n",
    "                nb_applic=container.find(class_='job-card-container__applicant-count job-card-container__footer-item job-card-container__footer-item--highlighted t-bold inline-flex align-items-center')\n",
    "                Number_applicants.append(nb_applic.get_text(strip= True))\n",
    "            except:\n",
    "                Number_applicants.append('none')\n",
    "\n",
    "            try:        \n",
    "                loca=container.find(class_='job-card-container__metadata-item')\n",
    "                location.append(loca.get_text(strip= True))\n",
    "            except:\n",
    "                location.append('none')\n",
    "            try:        \n",
    "                working=container.find(class_='job-card-container__metadata-item job-card-container__metadata-item--workplace-type')\n",
    "                working_Place.append(working.get_text(strip= True))\n",
    "            except:\n",
    "                working_Place.append('none')\n",
    "\n",
    "    company = comp\n",
    "    page = \"https://www.linkedin.com/jobs/search/?geoId=105015875&keywords=\"+company+\"%20jobs\"\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    # driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "    driver.set_window_size(900,800)\n",
    "    connect_to_linkedin ()\n",
    "    for numb in range(10):\n",
    "        sleep(1)\n",
    "        driver.get(page+'&start='+str(numb*25)) \n",
    "        sleep(1)\n",
    "        scrolling_function ()\n",
    "        sleep(2)\n",
    "        src =driver.page_source\n",
    "        soup =BeautifulSoup(src, 'lxml')\n",
    "        get_linkedin_jobs (soup)\n",
    "\n",
    "    jobs = pd.DataFrame(\n",
    "            {'Job_post_date': Job_post_date,\n",
    "             'company_name': company_name,\n",
    "             'job_title': job_title, \n",
    "             \"Number_applicants\": Number_applicants,\n",
    "             \"Location\": location,\n",
    "             \"working_Place\": working_Place,\n",
    "             \"job_links\":job_links,\n",
    "\n",
    "            })\n",
    "\n",
    "    company=comp\n",
    "    file_name= company+'_linkedin_jobs_df'\n",
    "    hdfs_url = \"http://localhost:9870/\"\n",
    "    hdfs_user = \"chiheb\"\n",
    "    c = InsecureClient(hdfs_url, user=hdfs_user)\n",
    "    c.makedirs(\"/user/chiheb/\"+company) \n",
    "    with c.write(company+'/'+file_name, encoding = 'utf-8') as writer:\n",
    "        jobs.to_csv(writer,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
