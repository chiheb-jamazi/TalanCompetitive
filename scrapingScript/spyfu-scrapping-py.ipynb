{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from hdfs import InsecureClient\n",
    "# from selenium import webdriver\n",
    "# from bs4 import BeautifulSoup\n",
    "# from time import sleep \n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# import pandas as pd\n",
    "from getpass import getpass\n",
    "from time import sleep \n",
    "from selenium.common.exceptions import NoSuchAttributeException\n",
    "# from msedge.selenium_tools import Edge, EdgeOptions\n",
    "import csv\n",
    "import re\n",
    "k=input()\n",
    "websites=[]\n",
    "websites.append(k)\n",
    "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "sleep(2)\n",
    "browser.get('https://www.spyfu.com/overview/domain?query='+k)\n",
    "sleep(3)\n",
    "browser.maximize_window()\n",
    "sleep(1)\n",
    "src = browser.page_source\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "sleep(1)\n",
    "browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "sleep(1)\n",
    "backlinkss=[]\n",
    "backlinks=[]\n",
    "organic_keywordss=[]\n",
    "organic_keywords=[]\n",
    "paid_keywords=[]\n",
    "paid_keywordss=[]\n",
    "organic_competitorss=[]\n",
    "organic_competitorsss=[]\n",
    "paid_competitorss=[]\n",
    "paid_competitorsss=[]\n",
    "organic_keywrods_nbs=[]\n",
    "paid_keywrod_nbs=[]\n",
    "Est_Monthly_SEO_Clicks=[]\n",
    "Est_Monthly_SEO_Click_changes=[]\n",
    "Est_Monthly_PPC_Clicks=[]\n",
    "Est_Monthly_Google_Ad_Budgets=[]\n",
    "\n",
    "for website in websites:\n",
    "    \n",
    "        #organic keywords numbers\n",
    "    try :\n",
    "        keywords=soup.find_all('a',({'class':'keyword-count margin-bottom'}))\n",
    "        organic_keywrods_nb=keywords[0].get_text().strip()\n",
    "        organic_keywrods_nbs.append(organic_keywrods_nb)\n",
    "    except :\n",
    "        organic_keywrods_nbs='none'\n",
    "        \n",
    "        #paid keywords numbers\n",
    "    try :\n",
    "        paid_keywrod_nb=keywords[1].get_text().strip()\n",
    "        paid_keywrod_nbs.append(paid_keywrod_nb)\n",
    "    except :\n",
    "        paid_keywrod_nbs='none'\n",
    "        \n",
    "        #number of clicks\n",
    "    \n",
    "    clicks=soup.find_all('div',({'class':'click-count'}))\n",
    "    try :\n",
    "        Est_Monthly_SEO_Click=clicks[0].get_text().strip()\n",
    "        Est_Monthly_SEO_Clicks.append(Est_Monthly_SEO_Click)\n",
    "    except :\n",
    "        Est_Monthly_SEO_Clicks='none' \n",
    "    try :\n",
    "        Est_Monthly_SEO_Click_change=clicks[1].get_text().strip()\n",
    "        Est_Monthly_SEO_Click_changes.append(Est_Monthly_SEO_Click_change)\n",
    "    except :\n",
    "        Est_Monthly_SEO_Clicks='none'     \n",
    "    try :\n",
    "        Est_Monthly_PPC_Click=clicks[2].get_text().strip()\n",
    "        Est_Monthly_PPC_Clicks.append(Est_Monthly_PPC_Click)\n",
    "    except :\n",
    "        Est_Monthly_PPC_Clicks='none'     \n",
    "    try :\n",
    "        Est_Monthly_Google_Ad_Budget=clicks[3].get_text().strip()\n",
    "        Est_Monthly_Google_Ad_Budgets.append(Est_Monthly_Google_Ad_Budget)\n",
    "    except :\n",
    "        Est_Monthly_Google_Ad_Budgets='none' \n",
    "        \n",
    "        #organic competitors\n",
    "        \n",
    "    try :\n",
    "        organic_competetion=soup.find('div',({'class':'competitor-panel sf-panel sf-global-component tw-shadow'}))\n",
    "        organic_competitors=organic_competetion.find_all('label',({'class':'sf-simple-tornado-chart-label ellipsis'}))\n",
    "        for i in range(5):\n",
    "            organic_competitorss.append(organic_competitors[i].get_text().strip())\n",
    "        organic_competitorsss.append(organic_competitorss)\n",
    "    except :\n",
    "        organic_competitorsss='none' \n",
    "        \n",
    "        #paid competitors\n",
    "        \n",
    "    try :\n",
    "        paid_competetion=soup.find_all('div',({'class':'competitor-panel sf-panel sf-global-component tw-shadow'}))\n",
    "        paid_competitors=paid_competetion[1].find_all('label',({'class':'sf-simple-tornado-chart-label ellipsis'}))\n",
    "        for i in range(5):\n",
    "            paid_competitorss.append(paid_competitors[i].get_text().strip())\n",
    "        paid_competitorsss.append(paid_competitorss)\n",
    "    except :\n",
    "        paid_competitorsss='none'    \n",
    "        \n",
    "    xk=soup.find_all('div',({'class':'sf-grid-cell tablet-6'}))\n",
    "\n",
    "        #organic keywords\n",
    "        \n",
    "    try :\n",
    "        hh=soup.find_all('td',({'class':'term-cell sf-global-component sf-table-cell'}))\n",
    "        for i in range(5):\n",
    "            organic_keywords.append(hh[i].get_text().strip())\n",
    "        organic_keywordss.append(organic_keywords)\n",
    "    except :\n",
    "        organic_keywordss='none' \n",
    "        #paid keywords\n",
    "    try :\n",
    "        for i in range(5,10):  \n",
    "            paid_keywords.append(hh[i].get_text().strip())\n",
    "        paid_keywordss.append(paid_keywords)\n",
    "    except :\n",
    "        paid_keywordss='none' \n",
    "        \n",
    "        #backlinks\n",
    "        \n",
    "    try :\n",
    "        s='spyfu'\n",
    "        elems=browser.find_elements_by_css_selector(\"[target='_blank']\")\n",
    "        for elem in elems :\n",
    "            h=str(elem.get_attribute('href'))\n",
    "            if (k not in h) and (s not in h):\n",
    "                backlinks.append(h) \n",
    "        backlinkss.append(backlinks)\n",
    "    except :\n",
    "        backlinkss='none'\n",
    "    \n",
    "\n",
    "informations = ({'websites':websites,'backlinkss': backlinkss, 'organic_keywordss': organic_keywordss,  'paid_keywordss': paid_keywordss, 'organic_competitorsss': organic_competitorsss, 'paid_competitorsss':paid_competitorsss ,\n",
    "                 'organic_keywrods_nbs':organic_keywrods_nbs , 'Est_Monthly_SEO_Clicks':Est_Monthly_SEO_Clicks,'Est_Monthly_SEO_Click_changes':Est_Monthly_SEO_Click_changes , \n",
    "                 'Est_Monthly_PPC_Clicks':Est_Monthly_PPC_Clicks , 'Est_Monthly_Google_Ad_Budgets':Est_Monthly_Google_Ad_Budgets }) \n",
    "df = pd.DataFrame(informations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "company='accenture'\n",
    "file_name= company.upper()+'_Spyfu_df'\n",
    "hdfs_url = \"http://localhost:9870/\"\n",
    "hdfs_user = \"chiheb\"\n",
    "c = InsecureClient(hdfs_url, user=hdfs_user)\n",
    "c.makedirs(\"/user/chiheb/accenture\") \n",
    "with c.write('accenture/'+file_name, encoding = 'utf-8') as writer:\n",
    "    df.to_csv(writer,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
